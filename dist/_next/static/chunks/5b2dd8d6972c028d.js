(globalThis.TURBOPACK||(globalThis.TURBOPACK=[])).push(["object"==typeof document?document.currentScript:void 0,75254,e=>{"use strict";var t=e.i(71645);let a=e=>{let t=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,t,a)=>a?a.toUpperCase():t.toLowerCase());return t.charAt(0).toUpperCase()+t.slice(1)},i=(...e)=>e.filter((e,t,a)=>!!e&&""!==e.trim()&&a.indexOf(e)===t).join(" ").trim();var r={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let n=(0,t.forwardRef)(({color:e="currentColor",size:a=24,strokeWidth:n=2,absoluteStrokeWidth:s,className:o="",children:l,iconNode:c,...d},u)=>(0,t.createElement)("svg",{ref:u,...r,width:a,height:a,stroke:e,strokeWidth:s?24*Number(n)/Number(a):n,className:i("lucide",o),...!l&&!(e=>{for(let t in e)if(t.startsWith("aria-")||"role"===t||"title"===t)return!0})(d)&&{"aria-hidden":"true"},...d},[...c.map(([e,a])=>(0,t.createElement)(e,a)),...Array.isArray(l)?l:[l]])),s=(e,r)=>{let s=(0,t.forwardRef)(({className:s,...o},l)=>(0,t.createElement)(n,{ref:l,iconNode:r,className:i(`lucide-${a(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,s),...o}));return s.displayName=a(e),s};e.s(["default",()=>s],75254)},50682,e=>{"use strict";let t=(0,e.i(75254).default)("github",[["path",{d:"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4",key:"tonef"}],["path",{d:"M9 18c-4.51 2-5-2-7-2",key:"9comsn"}]]);e.s(["Github",()=>t],50682)},94808,e=>{"use strict";let t=[{id:"1",slug:"real-time-crack-detection",title:"Real-Time Crack Detection & Segmentation",shortDescription:"Industrial-grade computer vision pipeline for structural crack detection using state-of-the-art models with full deployment.",longDescription:"Production-grade computer vision pipeline that detects and segments structural cracks in real-time with 95.3% mAPâ€”15% better than existing solutions. Built at AlgoLabs for infrastructure monitoring.",category:"computer-vision",tags:["Computer Vision","Production ML","Docker","Streamlit"],technologies:["YOLOv8","SAM","Detectron2","PyTorch","Docker","Streamlit","FastAPI","LabelMe"],featured:!0,githubUrl:"https://github.com/bhuvneshsahu01/Real-Time-Crack-Detection-and-Segmentation",highlights:["Created custom dataset: 1,200+ images with LabelMe annotations, handling extreme class imbalance (cracks: 3% of pixels)","Benchmarked 3 SOTA models: YOLOv8 (fastest), SAM (best segmentation), Detectron2 (best balance)","Selected YOLOv8-L based on speed/accuracy trade-off: 95.3% mAP @ 30 FPS on RTX 3090","Built FastAPI backend + Streamlit frontend, containerized with Docker for edge deployment"],impact:"Deployed at AlgoLabs - now processing 10K+ images/day in production. Demonstrates ability to build production CV systems from data collection through deployment.",problem:"Manual structural inspection is slow, expensive, and misses 20-30% of critical cracks. A single missed crack in a bridge can lead to catastrophic failure, costing lives and millions in repairs.",technicalApproach:["Dataset Creation: Built custom dataset with 1,200+ images using LabelMe, implementing careful class balancing strategies for extreme imbalance (cracks represent only 3% of pixels)","Model Selection: Systematically benchmarked YOLOv8 (optimized for speed), SAM (best segmentation quality), and Detectron2 (balanced performance)","Optimization: Selected YOLOv8-L for optimal speed/accuracy trade-off, achieving 95.3% mAP @ 30 FPS on RTX 3090","Deployment Architecture: Built FastAPI backend for model serving, Streamlit frontend for visualization, containerized entire stack with Docker for consistent edge deployment"],results:["95.3% mAP on test set (vs 82% baseline Faster R-CNN) - 13 percentage point improvement","30 FPS inference speed - real-time capable for video processing","89.4% IoU on segmentation masks - high-quality pixel-level detection","Processing 10K+ images/day in production at AlgoLabs","91% inter-annotator agreement during dataset curation"],challenges:["Class Imbalance: Cracks represent only 3% of pixels. Solution: Implemented focal loss and extensive data augmentation (flips, rotation, brightness adjustments)","Edge Deployment: Model too large for edge devices. Solution: Applied model quantization reducing size by 60% with <2% accuracy loss","Real-World Variability: Cracks appear under diverse conditions. Solution: Trained on varied lighting, angles, crack types, and surface materials","Segmentation vs Detection Trade-off: Balanced precision requirements with inference speed for real-time use"],learnings:"Production computer vision is 20% model training, 80% handling edge cases, deployment, and monitoring. The model that achieves 95% accuracy in notebooks often fails in production due to distribution shift, lighting variations, and deployment constraints. Success requires systematic data collection, rigorous evaluation across diverse conditions, and production-first architecture decisions."},{id:"2",slug:"tv-series-nlp-analyzer",title:"End-to-End NLP Application with LLMs",shortDescription:"Comprehensive NLP system combining web scraping, zero-shot classification, network analysis, and LLM fine-tuning for TV series content analysis.",longDescription:"Multi-faceted NLP project featuring theme extraction via zero-shot classification, interactive character relationship graphs, DistilBERT fine-tuning for text classification, and LLaMA 3.1 fine-tuning with PEFT/QLoRA for conversational AI.",category:"nlp",tags:["LLM Fine-tuning","Zero-Shot","Network Analysis","NLP Pipeline"],technologies:["LLaMA 3.1","BART","DistilBERT","PEFT/QLoRA","SpaCy","NetworkX","PyVis","Gradio"],featured:!0,githubUrl:"https://github.com/bhuvneshsahu01/TV-Series-analyzer",highlights:["Web-scraped 3 datasets (subtitles, descriptions, transcripts) using Scrapy","Zero-shot theme classification using BART-L-MNLI","Built interactive character network with SpaCy NER + NetworkX + PyVis","Fine-tuned LLaMA 3.1 (8B) with PEFT/QLoRA for character chatbot","Fine-tuned DistilBERT for domain-specific classification"],impact:"Showcases modern NLP/LLM pipeline construction, fine-tuning expertise, and ability to combine multiple advanced techniques into a cohesive application"},{id:"3",slug:"rag-multi-doc-chatbot",title:"RAG-Based Multi-Document ChatBot with Voice",shortDescription:"Production-ready conversational AI system using RAG architecture with vector databases, voice interface, and deployed on Hugging Face Spaces.",longDescription:"Interactive Q&A application enabling natural conversations with multiple documents. Features open-source embeddings, ChromaDB vector storage, Whisper voice input, Gemini TTS output, and LangChain orchestration.",category:"gen-ai",tags:["RAG","Vector DB","Voice AI","LangChain"],technologies:["LangChain","ChromaDB","Whisper","Gemini TTS","LLaMA","ChatGroq","Hugging Face"],featured:!0,githubUrl:"https://github.com/bhuvneshsahu01/Multi-Doc-RAG-Chatbot",liveUrl:"https://huggingface.co/spaces/bhuvneshsahu01/rag-chatbot",highlights:["Built RAG pipeline with ChromaDB vector storage for efficient similarity search","Integrated Whisper (audio input) + Gemini TTS (audio output) for voice interface","Used LLaMA Scout LLM via ChatGroq with ConversationBufferMemory","Deployed on Hugging Face Spaces for public access"],impact:"Demonstrates proficiency in modern Gen-AI stack (RAG, vector DBs, LLMs) and ability to build production-ready applications with multi-modal interfaces"},{id:"4",slug:"music-genre-classification",title:"Music Genre Classification with Hybrid Deep Learning",shortDescription:"Advanced audio classification using hybrid ANN+CNN architecture with Mel spectrograms, feature engineering, and Bayesian optimization.",longDescription:"Built comprehensive audio ML pipeline extracting MFCCs, chroma, spectral features, and tempo. Implemented hybrid Functional API combining ANN for audio features and CNN for Mel spectrograms, with Bayesian hyperparameter tuning.",category:"ml",tags:["Audio ML","Deep Learning","Feature Engineering","Bayesian Optimization"],technologies:["PyTorch","Librosa","CNN","ANN","XGBoost","Scikit-learn","Bayesian Optimization"],featured:!0,githubUrl:"https://github.com/bhuvneshsahu01/Music-Genre-Classification",highlights:["Dataset: 10 genres, 100 samples per genre (30s audio clips)","Extracted audio features (MFCCs, chroma, spectral contrast) + PCA reduction","Compared 6 ML models: LR, SVC, Decision Trees, NB, KNN, RF, XGBoost","Built hybrid Functional API: ANN for features + CNN for spectrograms","Performed Bayesian hyperparameter optimization with comparative analysis table"],impact:"Shows deep learning architecture design skills, signal processing knowledge, and rigorous experimentation methodology"},{id:"5",slug:"api-assistant-system",title:"System-Agnostic AI API Assistant",shortDescription:"LLM-powered assistant enabling natural language interaction with any API-based system through intelligent workflow generation.",longDescription:"Built production agentic AI system at Coriolis Technologies that reduced support ticket volume by 40% through intelligent workflow automation. Converts natural language requests into executable multi-step API workflows.",category:"gen-ai",tags:["LLM Agents","API Integration","Workflow Automation","Production System"],technologies:["LangChain","OpenAPI","Groq","Mistral","GPT-3.5","FastAPI","Workflow Orchestration"],featured:!0,githubUrl:"#",highlights:["Reduced support ticket volume by 40% through intelligent automation of repetitive tasks (data retrieval, report generation)","Built production system serving 500+ internal users with 87% success rate on complex multi-step workflows","Designed system-agnostic architecture working with any OpenAPI-compliant API without code changes","Saved estimated 15 hours/week of support engineer time (~$30K annual cost reduction)"],impact:"Built during Coriolis internship - demonstrates ability to build production LLM systems that solve real business problems and reduce operational overhead. The 40% ticket reduction and $30K savings show tangible business value.",problem:'Support team spent 15+ hours/week manually executing repetitive API tasks for internal users (e.g., "create a new user account with specific permissions", "generate quarterly usage report"). Each task required knowledge of complex API documentation, proper parameter formatting, and correct sequence of API calls. This created bottlenecks, delayed users, and prevented support engineers from focusing on complex issues.',technicalApproach:["Knowledge Base Creation: Parsed OpenAPI specifications into structured vector database, creating semantic search over 200+ API endpoints with parameter schemas and dependencies",'Intent Classification: Implemented LLM chain to decompose user natural language requests into structured intent + parameters (e.g., "create admin user for John" â†’ intent: create_user, params: {name: "John", role: "admin"})',"Workflow Planning: Built dependency-aware graph planner that sequences API calls (e.g., create user â†’ assign permissions â†’ send notification), handling parallel execution where possible","LLM Evaluation: Tested 6 models (GPT-3.5, Mistral-7B, Llama-3.1, Qwen-2.5, Gemini) - selected GPT-3.5-turbo for best cost/accuracy trade-off (87% success vs 92% for GPT-4 at 10x cost)"],results:["40% reduction in support ticket volume (from ~150/week to ~90/week)","500+ internal users actively using the system","87% success rate on complex multi-step workflows requiring 3+ API calls","15 hours/week saved in support engineer time (estimated $30K annual savings)","Average task completion time reduced from 10 minutes (manual) to 30 seconds (automated)","System handles 10+ different API systems (GitLab, Kubernetes, Slack, internal tools)"],challenges:["API Documentation Quality: Many internal APIs had incomplete/outdated OpenAPI specs. Solution: Built semi-automated documentation enhancement system with LLM-assisted parameter inference","Error Handling: LLMs hallucinate invalid parameters. Solution: Implemented strict schema validation + fallback to ask user for clarification when confidence < 0.7","Complex Dependencies: Some workflows required conditional logic (if X fails, do Y). Solution: Built simple workflow DSL with branching support","Cost Control: GPT-4 was too expensive for 500 users. Solution: Systematic benchmarking showed GPT-3.5 achieved 87% vs 92% accuracy at 10x lower cost - acceptable trade-off"],learnings:"Production LLM systems require obsessive focus on error handling, cost optimization, and graceful degradation. The difference between 87% and 92% accuracy sounds small, but represents real user frustration. Key insight: most failures come from poor prompting and inadequate guardrails, not model limitations. Investing time in robust prompt engineering, schema validation, and user feedback loops delivers better ROI than upgrading models."},{id:"6",slug:"privacy-preserving-ml",title:"Comparative Study: Privacy-Preserving ML Techniques",shortDescription:"Research implementation comparing k-Anonymity, l-Diversity, and Differential Privacy with utility-risk tradeoff analysis.",longDescription:"Theoretical and practical study implementing three privacy models from scratch. Comprehensive evaluation of utility loss, risk measures, reconstruction risk, and privacy-utility tradeoffs on real datasets.",category:"ml",tags:["Privacy","Research","Statistical ML","Theory to Practice"],technologies:["Python","NumPy","Pandas","Statistical Modeling"],featured:!1,githubUrl:"#",highlights:["Implemented k-Anonymity, l-Diversity, and Differential Privacy from scratch","Comprehensive comparative analysis on utility loss and privacy guarantees","Evaluated reconstruction risk and information leakage metrics","Demonstrated practical tradeoffs between data utility and privacy protection"],impact:"Shows strong theoretical foundation in statistics and ability to translate academic concepts into practical implementations"}];function a(){return t.filter(e=>e.featured)}e.s(["getFeaturedProjects",()=>a,"projectCategories",0,{"gen-ai":{label:"Gen-AI & LLM",icon:"ðŸ¤–"},"computer-vision":{label:"Computer Vision",icon:"ðŸ‘ï¸"},nlp:{label:"NLP & Deep Learning",icon:"ðŸ’¬"},ml:{label:"Machine Learning",icon:"ðŸ“Š"}}])},63178,e=>{"use strict";var t=e.i(71645),a=(e,t,a,i,r,n,s,o)=>{let l=document.documentElement,c=["light","dark"];function d(t){var a;(Array.isArray(e)?e:[e]).forEach(e=>{let a="class"===e,i=a&&n?r.map(e=>n[e]||e):r;a?(l.classList.remove(...i),l.classList.add(n&&n[t]?n[t]:t)):l.setAttribute(e,t)}),a=t,o&&c.includes(a)&&(l.style.colorScheme=a)}if(i)d(i);else try{let e=localStorage.getItem(t)||a,i=s&&"system"===e?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":e;d(i)}catch(e){}},i=["light","dark"],r="(prefers-color-scheme: dark)",n="undefined"==typeof window,s=t.createContext(void 0),o={setTheme:e=>{},themes:[]},l=()=>{var e;return null!=(e=t.useContext(s))?e:o},c=e=>t.useContext(s)?t.createElement(t.Fragment,null,e.children):t.createElement(u,{...e}),d=["light","dark"],u=({forcedTheme:e,disableTransitionOnChange:a=!1,enableSystem:n=!0,enableColorScheme:o=!0,storageKey:l="theme",themes:c=d,defaultTheme:u=n?"system":"light",attribute:f="data-theme",value:b,children:y,nonce:v,scriptProps:x})=>{let[w,k]=t.useState(()=>h(l,u)),[L,A]=t.useState(()=>"system"===w?g():w),C=b?Object.values(b):c,N=t.useCallback(e=>{let t=e;if(!t)return;"system"===e&&n&&(t=g());let r=b?b[t]:t,s=a?p(v):null,l=document.documentElement,c=e=>{"class"===e?(l.classList.remove(...C),r&&l.classList.add(r)):e.startsWith("data-")&&(r?l.setAttribute(e,r):l.removeAttribute(e))};if(Array.isArray(f)?f.forEach(c):c(f),o){let e=i.includes(u)?u:null,a=i.includes(t)?t:e;l.style.colorScheme=a}null==s||s()},[v]),S=t.useCallback(e=>{let t="function"==typeof e?e(w):e;k(t);try{localStorage.setItem(l,t)}catch(e){}},[w]),P=t.useCallback(t=>{A(g(t)),"system"===w&&n&&!e&&N("system")},[w,e]);t.useEffect(()=>{let e=window.matchMedia(r);return e.addListener(P),P(e),()=>e.removeListener(P)},[P]),t.useEffect(()=>{let e=e=>{e.key===l&&(e.newValue?k(e.newValue):S(u))};return window.addEventListener("storage",e),()=>window.removeEventListener("storage",e)},[S]),t.useEffect(()=>{N(null!=e?e:w)},[e,w]);let j=t.useMemo(()=>({theme:w,setTheme:S,forcedTheme:e,resolvedTheme:"system"===w?L:w,themes:n?[...c,"system"]:c,systemTheme:n?L:void 0}),[w,S,e,L,n,c]);return t.createElement(s.Provider,{value:j},t.createElement(m,{forcedTheme:e,storageKey:l,attribute:f,enableSystem:n,enableColorScheme:o,defaultTheme:u,value:b,themes:c,nonce:v,scriptProps:x}),y)},m=t.memo(({forcedTheme:e,storageKey:i,attribute:r,enableSystem:n,enableColorScheme:s,defaultTheme:o,value:l,themes:c,nonce:d,scriptProps:u})=>{let m=JSON.stringify([r,i,o,e,c,l,n,s]).slice(1,-1);return t.createElement("script",{...u,suppressHydrationWarning:!0,nonce:"undefined"==typeof window?d:"",dangerouslySetInnerHTML:{__html:`(${a.toString()})(${m})`}})}),h=(e,t)=>{let a;if(!n){try{a=localStorage.getItem(e)||void 0}catch(e){}return a||t}},p=e=>{let t=document.createElement("style");return e&&t.setAttribute("nonce",e),t.appendChild(document.createTextNode("*,*::before,*::after{-webkit-transition:none!important;-moz-transition:none!important;-o-transition:none!important;-ms-transition:none!important;transition:none!important}")),document.head.appendChild(t),()=>{window.getComputedStyle(document.body),setTimeout(()=>{document.head.removeChild(t)},1)}},g=e=>(e||(e=window.matchMedia(r)),e.matches?"dark":"light");e.s(["ThemeProvider",()=>c,"useTheme",()=>l])},65733,e=>{"use strict";var t=e.i(43476),a=e.i(63178),i=e.i(71645),r=e.i(75254);let n=(0,r.default)("sun",[["circle",{cx:"12",cy:"12",r:"4",key:"4exip2"}],["path",{d:"M12 2v2",key:"tus03m"}],["path",{d:"M12 20v2",key:"1lh1kg"}],["path",{d:"m4.93 4.93 1.41 1.41",key:"149t6j"}],["path",{d:"m17.66 17.66 1.41 1.41",key:"ptbguv"}],["path",{d:"M2 12h2",key:"1t8f8n"}],["path",{d:"M20 12h2",key:"1q8mjw"}],["path",{d:"m6.34 17.66-1.41 1.41",key:"1m8zz5"}],["path",{d:"m19.07 4.93-1.41 1.41",key:"1shlcs"}]]),s=(0,r.default)("moon",[["path",{d:"M20.985 12.486a9 9 0 1 1-9.473-9.472c.405-.022.617.46.402.803a6 6 0 0 0 8.268 8.268c.344-.215.825-.004.803.401",key:"kfwtm"}]]);var o=e.i(75157);function l(){let{theme:e,setTheme:r}=(0,a.useTheme)(),[l,c]=(0,i.useState)(!1);return((0,i.useEffect)(()=>{c(!0)},[]),l)?(0,t.jsxs)("button",{onClick:()=>{r("light"===e?"dark":"light")},className:(0,o.cn)("relative w-12 h-12 flex items-center justify-center","rounded-lg glass cursor-pointer","transition-all duration-300","hover:border-accent-primary hover:-translate-y-0.5","hover:shadow-md overflow-hidden"),"aria-label":`Switch to ${"light"===e?"dark":"light"} mode`,children:[(0,t.jsx)(n,{className:(0,o.cn)("absolute w-6 h-6 transition-all duration-300","text-foreground-secondary hover:text-accent-primary","light"===e?"opacity-100 rotate-0 scale-100":"opacity-0 -rotate-90 scale-0")}),(0,t.jsx)(s,{className:(0,o.cn)("absolute w-6 h-6 transition-all duration-300","text-foreground-secondary hover:text-accent-primary","dark"===e?"opacity-100 rotate-0 scale-100":"opacity-0 rotate-90 scale-0")})]}):(0,t.jsx)("button",{className:"w-12 h-12 flex items-center justify-center rounded-lg bg-background-card border border-border","aria-label":"Toggle theme",children:(0,t.jsx)("div",{className:"w-6 h-6"})})}e.s(["ThemeToggle",()=>l],65733)},3265,e=>{"use strict";var t=e.i(43476),a=e.i(71645),i=e.i(75254);let r=(0,i.default)("menu",[["path",{d:"M4 5h16",key:"1tepv9"}],["path",{d:"M4 12h16",key:"1lakjw"}],["path",{d:"M4 19h16",key:"1djgab"}]]),n=(0,i.default)("x",[["path",{d:"M18 6 6 18",key:"1bl5f8"}],["path",{d:"m6 6 12 12",key:"d8bk6v"}]]);var s=e.i(75157),o=e.i(65733);let l=[{href:"#home",label:"Home"},{href:"#about",label:"About"},{href:"#experience",label:"Experience"},{href:"#projects",label:"Projects"},{href:"#skills",label:"Skills"},{href:"#contact",label:"Contact"}];function c(){let[e,i]=(0,a.useState)(!1),[c,d]=(0,a.useState)(!1),[u,m]=(0,a.useState)("home");(0,a.useEffect)(()=>{let e=()=>{for(let e of(i(window.scrollY>50),l.map(e=>e.href.substring(1)).reverse())){let t=document.getElementById(e);if(t&&t.getBoundingClientRect().top<=150){m(e);break}}};return window.addEventListener("scroll",e),()=>window.removeEventListener("scroll",e)},[]);let h=(e,t)=>{e.preventDefault(),d(!1);let a=t.substring(1),i=document.getElementById(a);if(i){let e=i.getBoundingClientRect().top+window.pageYOffset-100;window.scrollTo({top:e,behavior:"smooth"})}};return(0,t.jsx)("nav",{className:(0,s.cn)("fixed top-0 left-0 right-0 z-50","transition-all duration-300",e?"bg-background/80 backdrop-blur-xl border-b border-border shadow-sm":"bg-transparent"),children:(0,t.jsxs)("div",{className:"content-wrapper",style:{width:"100%",maxWidth:"1280px",marginLeft:"auto",marginRight:"auto",paddingLeft:"24px",paddingRight:"24px"},children:[(0,t.jsxs)("div",{className:"flex items-center justify-between h-20",children:[(0,t.jsxs)("a",{href:"#home",onClick:e=>h(e,"#home"),className:"flex items-center gap-2 group",children:[(0,t.jsx)("div",{className:"w-10 h-10 rounded-xl bg-gradient-to-br from-accent-primary to-accent-secondary flex items-center justify-center text-white font-bold font-heading text-lg shadow-lg shadow-accent-primary/25",children:"BS"}),(0,t.jsx)("span",{className:"hidden sm:block text-lg font-semibold font-heading text-foreground group-hover:text-accent-primary transition-colors",children:"Bhuvnesh Sahu"})]}),(0,t.jsx)("div",{className:"hidden lg:flex items-center gap-3",children:l.map(e=>{let a=u===e.href.substring(1);return(0,t.jsx)("a",{href:e.href,onClick:t=>h(t,e.href),className:(0,s.cn)("px-5 py-2.5 rounded-lg text-base font-medium transition-all duration-200",a?"text-accent-primary bg-accent-primary/10":"text-foreground-secondary hover:text-foreground hover:bg-background-tertiary"),children:e.label},e.href)})}),(0,t.jsxs)("div",{className:"flex items-center gap-3",children:[(0,t.jsx)(o.ThemeToggle,{}),(0,t.jsx)("button",{onClick:()=>d(!c),className:(0,s.cn)("lg:hidden w-10 h-10 flex items-center justify-center","rounded-lg bg-background-card border border-border","text-foreground-secondary hover:text-foreground","transition-all duration-200"),"aria-label":"Toggle menu",children:c?(0,t.jsx)(n,{className:"w-5 h-5"}):(0,t.jsx)(r,{className:"w-5 h-5"})})]})]}),(0,t.jsx)("div",{className:(0,s.cn)("lg:hidden overflow-hidden transition-all duration-300",c?"max-h-[400px] opacity-100 pb-6":"max-h-0 opacity-0"),children:(0,t.jsx)("div",{className:"pt-4 space-y-1 border-t border-border",children:l.map(e=>{let a=u===e.href.substring(1);return(0,t.jsx)("a",{href:e.href,onClick:t=>h(t,e.href),className:(0,s.cn)("block py-3 px-4 rounded-lg text-base font-medium transition-all duration-200",a?"bg-accent-primary/10 text-accent-primary":"text-foreground-secondary hover:bg-background-tertiary hover:text-foreground"),children:e.label},e.href)})})})]})})}e.s(["Navbar",()=>c],3265)},58234,e=>{"use strict";var t=e.i(43476),a=e.i(50682),i=e.i(51348),r=e.i(63488);let n=(0,e.i(75254).default)("heart",[["path",{d:"M2 9.5a5.5 5.5 0 0 1 9.591-3.676.56.56 0 0 0 .818 0A5.49 5.49 0 0 1 22 9.5c0 2.29-1.5 4-3 5.5l-5.492 5.313a2 2 0 0 1-3 .019L5 15c-1.5-1.5-3-3.2-3-5.5",key:"mvr1a0"}]]);e.i(94467);var s=e.i(29402);let o=[{href:"#about",label:"About"},{href:"#experience",label:"Experience"},{href:"#projects",label:"Projects"},{href:"#skills",label:"Skills"},{href:"#contact",label:"Contact"}];function l(){return(0,t.jsx)("footer",{className:"pt-24 pb-16 bg-background-secondary border-t border-border",children:(0,t.jsxs)("div",{className:"content-wrapper",style:{width:"100%",maxWidth:"1280px",marginLeft:"auto",marginRight:"auto",paddingLeft:"24px",paddingRight:"24px"},children:[(0,t.jsxs)("div",{className:"grid md:grid-cols-3 gap-16 mb-16",children:[(0,t.jsxs)("div",{style:{paddingTop:"8px"},children:[(0,t.jsxs)("div",{className:"flex items-center gap-3 mb-6",children:[(0,t.jsx)("div",{className:"w-12 h-12 rounded-xl bg-gradient-to-br from-accent-primary to-accent-secondary flex items-center justify-center text-white font-bold font-heading text-xl",children:"BS"}),(0,t.jsx)("span",{className:"text-2xl font-bold font-heading text-foreground",children:"Bhuvnesh Sahu"})]}),(0,t.jsx)("p",{className:"text-foreground-secondary text-base leading-relaxed mb-6",children:"Data Scientist passionate about building AI systems that make a real-world impact."}),(0,t.jsxs)("div",{className:"flex items-center gap-4",children:[(0,t.jsx)("a",{href:s.personalInfo.social.github,target:"_blank",rel:"noopener noreferrer",className:"w-12 h-12 flex items-center justify-center rounded-lg bg-background-card border border-border text-foreground-muted hover:text-accent-primary hover:border-accent-primary transition-all","aria-label":"GitHub",children:(0,t.jsx)(a.Github,{className:"w-6 h-6"})}),(0,t.jsx)("a",{href:s.personalInfo.social.linkedin,target:"_blank",rel:"noopener noreferrer",className:"w-12 h-12 flex items-center justify-center rounded-lg bg-background-card border border-border text-foreground-muted hover:text-accent-primary hover:border-accent-primary transition-all","aria-label":"LinkedIn",children:(0,t.jsx)(i.Linkedin,{className:"w-6 h-6"})}),(0,t.jsx)("a",{href:s.personalInfo.social.email,className:"w-12 h-12 flex items-center justify-center rounded-lg bg-background-card border border-border text-foreground-muted hover:text-accent-primary hover:border-accent-primary transition-all","aria-label":"Email",children:(0,t.jsx)(r.Mail,{className:"w-6 h-6"})})]})]}),(0,t.jsxs)("div",{style:{paddingTop:"8px"},children:[(0,t.jsx)("h3",{className:"text-lg font-semibold text-foreground uppercase tracking-wider mb-8",children:"Quick Links"}),(0,t.jsx)("ul",{className:"space-y-5",children:o.map(e=>(0,t.jsx)("li",{children:(0,t.jsx)("a",{href:e.href,onClick:t=>((e,t)=>{e.preventDefault();let a=t.substring(1),i=document.getElementById(a);if(i){let e=i.getBoundingClientRect().top+window.pageYOffset-100;window.scrollTo({top:e,behavior:"smooth"})}})(t,e.href),className:"text-foreground-secondary hover:text-accent-primary transition-colors text-lg",children:e.label})},e.href))})]}),(0,t.jsxs)("div",{style:{paddingTop:"8px"},children:[(0,t.jsx)("h3",{className:"text-lg font-semibold text-foreground uppercase tracking-wider mb-8",children:"Get in Touch"}),(0,t.jsxs)("ul",{className:"space-y-5 text-lg text-foreground-secondary",children:[(0,t.jsx)("li",{children:(0,t.jsx)("a",{href:`mailto:${s.personalInfo.email}`,className:"hover:text-accent-primary transition-colors",children:s.personalInfo.email})}),(0,t.jsx)("li",{children:s.personalInfo.location})]})]})]}),(0,t.jsxs)("div",{className:"pt-8 border-t border-border flex flex-col sm:flex-row items-center justify-between gap-4",children:[(0,t.jsxs)("p",{className:"text-sm text-foreground-muted",children:["Â© ",new Date().getFullYear()," Bhuvnesh Sahu. All rights reserved."]}),(0,t.jsxs)("p",{className:"text-sm text-foreground-muted flex items-center gap-1",children:["Built with ",(0,t.jsx)(n,{className:"w-4 h-4 text-accent-tertiary"})," using Next.js"]})]})]})})}e.s(["Footer",()=>l],58234)},18359,e=>{"use strict";var t=e.i(43476),a=e.i(63178);function i({children:e,...i}){return(0,t.jsx)(a.ThemeProvider,{attribute:"class",defaultTheme:"light",enableSystem:!1,disableTransitionOnChange:!1,...i,children:e})}e.s(["ThemeProvider",()=>i])}]);