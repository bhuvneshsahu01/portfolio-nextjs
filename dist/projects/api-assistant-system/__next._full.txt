1:"$Sreact.fragment"
2:I[18359,["/_next/static/chunks/83018d334d73546b.js","/_next/static/chunks/57295dd6a09d9778.js"],"ThemeProvider"]
3:I[3265,["/_next/static/chunks/83018d334d73546b.js","/_next/static/chunks/57295dd6a09d9778.js"],"Navbar"]
4:I[39756,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"default"]
5:I[37457,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"default"]
6:I[58234,["/_next/static/chunks/83018d334d73546b.js","/_next/static/chunks/57295dd6a09d9778.js"],"Footer"]
8:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
9:"$Sreact.suspense"
b:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"ViewportBoundary"]
d:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"MetadataBoundary"]
f:I[68027,[],"default"]
:HL["/_next/static/chunks/fa058511ebf21f41.css","style"]
:HL["/_next/static/media/0c89a48fa5027cee-s.p.4564287c.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
0:{"P":null,"b":"f2NP6DA-LcO-nEx8dBFpm","c":["","projects","api-assistant-system"],"q":"","i":false,"f":[[["",{"children":["projects",{"children":[["slug","api-assistant-system","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/fa058511ebf21f41.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/_next/static/chunks/83018d334d73546b.js","async":true,"nonce":"$undefined"}],["$","script","script-1",{"src":"/_next/static/chunks/57295dd6a09d9778.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"inter_7b064e0d-module__MOT0tq__variable space_grotesk_4f9f433b-module__fJfFLG__variable antialiased min-h-screen flex flex-col","children":["$","$L2",null,{"children":[["$","$L3",null,{}],["$","main",null,{"className":"flex-1","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L6",null,{}]]}]}]}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":["$L7",[["$","script","script-0",{"src":"/_next/static/chunks/c9a0df57e17de942.js","async":true,"nonce":"$undefined"}],["$","script","script-1",{"src":"/_next/static/chunks/7bea0d5e1a502b84.js","async":true,"nonce":"$undefined"}]],["$","$L8",null,{"children":["$","$9",null,{"name":"Next.MetadataOutlet","children":"$@a"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],["$","$1","h",{"children":[null,["$","$Lb",null,{"children":"$@c"}],["$","div",null,{"hidden":true,"children":["$","$Ld",null,{"children":["$","$9",null,{"name":"Next.Metadata","children":"$@e"}]}]}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],false]],"m":"$undefined","G":["$f",[]],"S":true}
10:I[29019,["/_next/static/chunks/83018d334d73546b.js","/_next/static/chunks/57295dd6a09d9778.js","/_next/static/chunks/c9a0df57e17de942.js","/_next/static/chunks/7bea0d5e1a502b84.js"],"ProjectCaseStudy"]
7:["$","$L10",null,{"project":{"id":"5","slug":"api-assistant-system","title":"System-Agnostic AI API Assistant","shortDescription":"LLM-powered assistant enabling natural language interaction with any API-based system through intelligent workflow generation.","longDescription":"Built production agentic AI system at Coriolis Technologies that reduced support ticket volume by 40% through intelligent workflow automation. Converts natural language requests into executable multi-step API workflows.","category":"gen-ai","tags":["LLM Agents","API Integration","Workflow Automation","Production System"],"technologies":["LangChain","OpenAPI","Groq","Mistral","GPT-3.5","FastAPI","Workflow Orchestration"],"featured":true,"githubUrl":"#","highlights":["Reduced support ticket volume by 40% through intelligent automation of repetitive tasks (data retrieval, report generation)","Built production system serving 500+ internal users with 87% success rate on complex multi-step workflows","Designed system-agnostic architecture working with any OpenAPI-compliant API without code changes","Saved estimated 15 hours/week of support engineer time (~$30K annual cost reduction)"],"impact":"Built during Coriolis internship - demonstrates ability to build production LLM systems that solve real business problems and reduce operational overhead. The 40% ticket reduction and $30K savings show tangible business value.","problem":"Support team spent 15+ hours/week manually executing repetitive API tasks for internal users (e.g., \"create a new user account with specific permissions\", \"generate quarterly usage report\"). Each task required knowledge of complex API documentation, proper parameter formatting, and correct sequence of API calls. This created bottlenecks, delayed users, and prevented support engineers from focusing on complex issues.","technicalApproach":["Knowledge Base Creation: Parsed OpenAPI specifications into structured vector database, creating semantic search over 200+ API endpoints with parameter schemas and dependencies","Intent Classification: Implemented LLM chain to decompose user natural language requests into structured intent + parameters (e.g., \"create admin user for John\" → intent: create_user, params: {name: \"John\", role: \"admin\"})","Workflow Planning: Built dependency-aware graph planner that sequences API calls (e.g., create user → assign permissions → send notification), handling parallel execution where possible","LLM Evaluation: Tested 6 models (GPT-3.5, Mistral-7B, Llama-3.1, Qwen-2.5, Gemini) - selected GPT-3.5-turbo for best cost/accuracy trade-off (87% success vs 92% for GPT-4 at 10x cost)"],"results":["40% reduction in support ticket volume (from ~150/week to ~90/week)","500+ internal users actively using the system","87% success rate on complex multi-step workflows requiring 3+ API calls","15 hours/week saved in support engineer time (estimated $30K annual savings)","Average task completion time reduced from 10 minutes (manual) to 30 seconds (automated)","System handles 10+ different API systems (GitLab, Kubernetes, Slack, internal tools)"],"challenges":["API Documentation Quality: Many internal APIs had incomplete/outdated OpenAPI specs. Solution: Built semi-automated documentation enhancement system with LLM-assisted parameter inference","Error Handling: LLMs hallucinate invalid parameters. Solution: Implemented strict schema validation + fallback to ask user for clarification when confidence < 0.7","Complex Dependencies: Some workflows required conditional logic (if X fails, do Y). Solution: Built simple workflow DSL with branching support","Cost Control: GPT-4 was too expensive for 500 users. Solution: Systematic benchmarking showed GPT-3.5 achieved 87% vs 92% accuracy at 10x lower cost - acceptable trade-off"],"learnings":"Production LLM systems require obsessive focus on error handling, cost optimization, and graceful degradation. The difference between 87% and 92% accuracy sounds small, but represents real user frustration. Key insight: most failures come from poor prompting and inadequate guardrails, not model limitations. Investing time in robust prompt engineering, schema validation, and user feedback loops delivers better ROI than upgrading models.","myRole":"Lead Engineer — Architected and implemented the complete system: OpenAPI parsing, LLM orchestration, workflow execution, and monitoring dashboard","productionization":{"cicd":"Containerized FastAPI service with automated testing. Docker Compose orchestration for local dev and production deployment. Blue-green deployment for zero-downtime updates.","monitoring":"Real-time dashboard tracking success rate (P99: 87%), latency (P99 < 500ms), API error types, and LLM token costs. Implemented automated alerts when success rate drops below 80%.","rollback":"Workflow versioning system allows instant rollback to previous workflow definitions. Compensation flows for partial failures (e.g., if step 3/5 fails, automatically undo steps 1-2).","optimization":"Reduced LLM costs 60% through prompt caching, response streaming, and GPT-3.5 vs GPT-4 benchmarking (87% vs 92% accuracy at 10x lower cost). Batched similar requests for efficiency."}}}]
c:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
11:I[27201,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"IconMark"]
e:[["$","title","0",{"children":"System-Agnostic AI API Assistant | Bhuvnesh Sahu"}],["$","meta","1",{"name":"description","content":"LLM-powered assistant enabling natural language interaction with any API-based system through intelligent workflow generation."}],["$","meta","2",{"name":"author","content":"Bhuvnesh Sahu"}],["$","meta","3",{"name":"keywords","content":"Machine Learning Engineer,ML Engineer Portfolio,Production AI Engineer,GenAI Engineer,Computer Vision Engineer,LLM Engineer,Agentic AI,RAG,NLP,Deep Learning,Python,PyTorch,LangChain"}],["$","meta","4",{"name":"creator","content":"Bhuvnesh Sahu"}],["$","meta","5",{"name":"robots","content":"index, follow"}],["$","meta","6",{"property":"og:title","content":"Bhuvnesh Sahu | ML Engineer | Production GenAI & Computer Vision"}],["$","meta","7",{"property":"og:description","content":"Machine Learning Engineer building production AI systems. Shipped 5+ ML systems with measurable business impact."}],["$","meta","8",{"property":"og:url","content":"https://bhuvneshsahu.com"}],["$","meta","9",{"property":"og:site_name","content":"Bhuvnesh Sahu - ML Engineer Portfolio"}],["$","meta","10",{"property":"og:locale","content":"en_US"}],["$","meta","11",{"property":"og:image","content":"https://bhuvneshsahu.com/images/og-image.png"}],["$","meta","12",{"property":"og:image:width","content":"1200"}],["$","meta","13",{"property":"og:image:height","content":"630"}],["$","meta","14",{"property":"og:image:alt","content":"Bhuvnesh Sahu - ML Engineer | Production GenAI & Computer Vision"}],["$","meta","15",{"property":"og:type","content":"website"}],["$","meta","16",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","17",{"name":"twitter:title","content":"Bhuvnesh Sahu | ML Engineer | Production GenAI & Computer Vision"}],["$","meta","18",{"name":"twitter:description","content":"Machine Learning Engineer building production AI systems with measurable business impact."}],["$","meta","19",{"name":"twitter:image","content":"https://bhuvneshsahu.com/images/og-image.png"}],["$","link","20",{"rel":"icon","href":"/favicon.ico?favicon.0b3bf435.ico","sizes":"256x256","type":"image/x-icon"}],["$","$L11","21",{}]]
a:null
