1:"$Sreact.fragment"
2:I[29019,["/_next/static/chunks/5b2dd8d6972c028d.js","/_next/static/chunks/57295dd6a09d9778.js","/_next/static/chunks/aa024a7c33692215.js","/_next/static/chunks/e777581372c34758.js"],"ProjectCaseStudy"]
6:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
7:"$Sreact.suspense"
0:{"buildId":"a2preHjmv5Jzi5jE3XqKB","rsc":["$","$1","c",{"children":[["$","$L2",null,{"project":{"id":"5","slug":"api-assistant-system","title":"System-Agnostic AI API Assistant","shortDescription":"LLM-powered assistant enabling natural language interaction with any API-based system through intelligent workflow generation.","longDescription":"Built production agentic AI system at Coriolis Technologies that reduced support ticket volume by 40% through intelligent workflow automation. Converts natural language requests into executable multi-step API workflows.","category":"gen-ai","tags":["LLM Agents","API Integration","Workflow Automation","Production System"],"technologies":["LangChain","OpenAPI","Groq","Mistral","GPT-3.5","FastAPI","Workflow Orchestration"],"featured":true,"githubUrl":"#","highlights":["Reduced support ticket volume by 40% through intelligent automation of repetitive tasks (data retrieval, report generation)","Built production system serving 500+ internal users with 87% success rate on complex multi-step workflows","Designed system-agnostic architecture working with any OpenAPI-compliant API without code changes","Saved estimated 15 hours/week of support engineer time (~$30K annual cost reduction)"],"impact":"Built during Coriolis internship - demonstrates ability to build production LLM systems that solve real business problems and reduce operational overhead. The 40% ticket reduction and $30K savings show tangible business value.","problem":"Support team spent 15+ hours/week manually executing repetitive API tasks for internal users (e.g., \"create a new user account with specific permissions\", \"generate quarterly usage report\"). Each task required knowledge of complex API documentation, proper parameter formatting, and correct sequence of API calls. This created bottlenecks, delayed users, and prevented support engineers from focusing on complex issues.","technicalApproach":["Knowledge Base Creation: Parsed OpenAPI specifications into structured vector database, creating semantic search over 200+ API endpoints with parameter schemas and dependencies","Intent Classification: Implemented LLM chain to decompose user natural language requests into structured intent + parameters (e.g., \"create admin user for John\" → intent: create_user, params: {name: \"John\", role: \"admin\"})","Workflow Planning: Built dependency-aware graph planner that sequences API calls (e.g., create user → assign permissions → send notification), handling parallel execution where possible","LLM Evaluation: Tested 6 models (GPT-3.5, Mistral-7B, Llama-3.1, Qwen-2.5, Gemini) - selected GPT-3.5-turbo for best cost/accuracy trade-off (87% success vs 92% for GPT-4 at 10x cost)"],"results":["40% reduction in support ticket volume (from ~150/week to ~90/week)","500+ internal users actively using the system","87% success rate on complex multi-step workflows requiring 3+ API calls","15 hours/week saved in support engineer time (estimated $30K annual savings)","Average task completion time reduced from 10 minutes (manual) to 30 seconds (automated)","System handles 10+ different API systems (GitLab, Kubernetes, Slack, internal tools)"],"challenges":["API Documentation Quality: Many internal APIs had incomplete/outdated OpenAPI specs. Solution: Built semi-automated documentation enhancement system with LLM-assisted parameter inference","Error Handling: LLMs hallucinate invalid parameters. Solution: Implemented strict schema validation + fallback to ask user for clarification when confidence < 0.7","Complex Dependencies: Some workflows required conditional logic (if X fails, do Y). Solution: Built simple workflow DSL with branching support","Cost Control: GPT-4 was too expensive for 500 users. Solution: Systematic benchmarking showed GPT-3.5 achieved 87% vs 92% accuracy at 10x lower cost - acceptable trade-off"],"learnings":"Production LLM systems require obsessive focus on error handling, cost optimization, and graceful degradation. The difference between 87% and 92% accuracy sounds small, but represents real user frustration. Key insight: most failures come from poor prompting and inadequate guardrails, not model limitations. Investing time in robust prompt engineering, schema validation, and user feedback loops delivers better ROI than upgrading models."}}],["$L3","$L4"],"$L5"]}],"loading":null,"isPartial":false}
3:["$","script","script-0",{"src":"/_next/static/chunks/aa024a7c33692215.js","async":true}]
4:["$","script","script-1",{"src":"/_next/static/chunks/e777581372c34758.js","async":true}]
5:["$","$L6",null,{"children":["$","$7",null,{"name":"Next.MetadataOutlet","children":"$@8"}]}]
8:null
