1:"$Sreact.fragment"
2:I[29019,["/_next/static/chunks/83018d334d73546b.js","/_next/static/chunks/57295dd6a09d9778.js","/_next/static/chunks/c9a0df57e17de942.js","/_next/static/chunks/7bea0d5e1a502b84.js"],"ProjectCaseStudy"]
6:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
7:"$Sreact.suspense"
0:{"buildId":"f2NP6DA-LcO-nEx8dBFpm","rsc":["$","$1","c",{"children":[["$","$L2",null,{"project":{"id":"1","slug":"real-time-crack-detection","title":"Real-Time Crack Detection & Segmentation","shortDescription":"Industrial-grade computer vision pipeline for structural crack detection using state-of-the-art models with full deployment.","longDescription":"Production-grade computer vision pipeline that detects and segments structural cracks in real-time with 95.3% mAP—15% better than existing solutions. Built at AlgoLabs for infrastructure monitoring.","category":"computer-vision","tags":["Computer Vision","Production ML","Docker","Streamlit"],"technologies":["YOLOv8","SAM","Detectron2","PyTorch","Docker","Streamlit","FastAPI","LabelMe"],"featured":true,"githubUrl":"https://github.com/bhuvneshsahu01/Real-Time-Crack-Detection-and-Segmentation","highlights":["Created custom dataset: 1,200+ images with LabelMe annotations, handling extreme class imbalance (cracks: 3% of pixels)","Benchmarked 3 SOTA models: YOLOv8 (fastest), SAM (best segmentation), Detectron2 (best balance)","Selected YOLOv8-L based on speed/accuracy trade-off: 95.3% mAP @ 30 FPS on RTX 3090","Built FastAPI backend + Streamlit frontend, containerized with Docker for edge deployment"],"impact":"Deployed at AlgoLabs - now processing 10K+ images/day in production. Demonstrates ability to build production CV systems from data collection through deployment.","problem":"Manual structural inspection is slow, expensive, and misses 20-30% of critical cracks. A single missed crack in a bridge can lead to catastrophic failure, costing lives and millions in repairs.","technicalApproach":["Dataset Creation: Built custom dataset with 1,200+ images using LabelMe, implementing careful class balancing strategies for extreme imbalance (cracks represent only 3% of pixels)","Model Selection: Systematically benchmarked YOLOv8 (optimized for speed), SAM (best segmentation quality), and Detectron2 (balanced performance)","Optimization: Selected YOLOv8-L for optimal speed/accuracy trade-off, achieving 95.3% mAP @ 30 FPS on RTX 3090","Deployment Architecture: Built FastAPI backend for model serving, Streamlit frontend for visualization, containerized entire stack with Docker for consistent edge deployment"],"results":["95.3% mAP on test set (vs 82% baseline Faster R-CNN) - 13 percentage point improvement","30 FPS inference speed - real-time capable for video processing","89.4% IoU on segmentation masks - high-quality pixel-level detection","Processing 10K+ images/day in production at AlgoLabs","91% inter-annotator agreement during dataset curation"],"challenges":["Class Imbalance: Cracks represent only 3% of pixels. Solution: Implemented focal loss and extensive data augmentation (flips, rotation, brightness adjustments)","Edge Deployment: Model too large for edge devices. Solution: Applied model quantization reducing size by 60% with <2% accuracy loss","Real-World Variability: Cracks appear under diverse conditions. Solution: Trained on varied lighting, angles, crack types, and surface materials","Segmentation vs Detection Trade-off: Balanced precision requirements with inference speed for real-time use"],"learnings":"Production computer vision is 20% model training, 80% handling edge cases, deployment, and monitoring. The model that achieves 95% accuracy in notebooks often fails in production due to distribution shift, lighting variations, and deployment constraints. Success requires systematic data collection, rigorous evaluation across diverse conditions, and production-first architecture decisions.","myRole":"Lead Engineer — Owned end-to-end pipeline from data collection and annotation through model training, optimization, and production deployment","productionization":{"cicd":"Containerized with Docker for consistent deployment across edge devices. Automated build pipeline ensures reproducible deployments.","monitoring":"Implemented latency tracking (45ms average CPU inference), accuracy monitoring on production data, and automated alerting for distribution drift.","rollback":"Model versioning with MLflow enables instant rollback to previous versions if accuracy degrades. Maintained 3 model versions for A/B testing.","optimization":"Applied TensorRT quantization (FP32 → INT8) reducing model size 60% and inference time to 45ms on CPU while maintaining 95%+ mAP. Enables real-time edge deployment."}}}],["$L3","$L4"],"$L5"]}],"loading":null,"isPartial":false}
3:["$","script","script-0",{"src":"/_next/static/chunks/c9a0df57e17de942.js","async":true}]
4:["$","script","script-1",{"src":"/_next/static/chunks/7bea0d5e1a502b84.js","async":true}]
5:["$","$L6",null,{"children":["$","$7",null,{"name":"Next.MetadataOutlet","children":"$@8"}]}]
8:null
