1:"$Sreact.fragment"
2:I[29019,["/_next/static/chunks/83018d334d73546b.js","/_next/static/chunks/57295dd6a09d9778.js","/_next/static/chunks/c9a0df57e17de942.js","/_next/static/chunks/7bea0d5e1a502b84.js"],"ProjectCaseStudy"]
3:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
4:"$Sreact.suspense"
0:{"buildId":"f2NP6DA-LcO-nEx8dBFpm","rsc":["$","$1","c",{"children":[["$","$L2",null,{"project":{"id":"6","slug":"privacy-preserving-ml","title":"Comparative Study: Privacy-Preserving ML Techniques","shortDescription":"Research implementation comparing k-Anonymity, l-Diversity, and Differential Privacy with utility-risk tradeoff analysis.","longDescription":"Theoretical and practical study implementing three privacy models from scratch. Comprehensive evaluation of utility loss, risk measures, reconstruction risk, and privacy-utility tradeoffs on real datasets.","category":"ml","tags":["Privacy","Research","Statistical ML","Theory to Practice"],"technologies":["Python","NumPy","Pandas","Statistical Modeling"],"featured":false,"githubUrl":"#","highlights":["Implemented k-Anonymity, l-Diversity, and Differential Privacy from scratch","Comprehensive comparative analysis on utility loss and privacy guarantees","Evaluated reconstruction risk and information leakage metrics","Demonstrated practical tradeoffs between data utility and privacy protection"],"impact":"Shows strong theoretical foundation in statistics and ability to translate academic concepts into practical implementations"}}],[["$","script","script-0",{"src":"/_next/static/chunks/c9a0df57e17de942.js","async":true}],["$","script","script-1",{"src":"/_next/static/chunks/7bea0d5e1a502b84.js","async":true}]],["$","$L3",null,{"children":["$","$4",null,{"name":"Next.MetadataOutlet","children":"$@5"}]}]]}],"loading":null,"isPartial":false}
5:null
