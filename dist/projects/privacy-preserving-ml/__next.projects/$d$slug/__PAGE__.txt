1:"$Sreact.fragment"
2:I[29019,["/_next/static/chunks/5b2dd8d6972c028d.js","/_next/static/chunks/76e7e7ffe7304dbf.js","/_next/static/chunks/aa024a7c33692215.js","/_next/static/chunks/e777581372c34758.js"],"ProjectCaseStudy"]
3:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
4:"$Sreact.suspense"
0:{"buildId":"sh59HwsNBVbk6Ac8LFg9M","rsc":["$","$1","c",{"children":[["$","$L2",null,{"project":{"id":"6","slug":"privacy-preserving-ml","title":"Comparative Study: Privacy-Preserving ML Techniques","shortDescription":"Research implementation comparing k-Anonymity, l-Diversity, and Differential Privacy with utility-risk tradeoff analysis.","longDescription":"Theoretical and practical study implementing three privacy models from scratch. Comprehensive evaluation of utility loss, risk measures, reconstruction risk, and privacy-utility tradeoffs on real datasets.","category":"ml","tags":["Privacy","Research","Statistical ML","Theory to Practice"],"technologies":["Python","NumPy","Pandas","Statistical Modeling"],"featured":false,"githubUrl":"#","highlights":["Implemented k-Anonymity, l-Diversity, and Differential Privacy from scratch","Comprehensive comparative analysis on utility loss and privacy guarantees","Evaluated reconstruction risk and information leakage metrics","Demonstrated practical tradeoffs between data utility and privacy protection"],"impact":"Shows strong theoretical foundation in statistics and ability to translate academic concepts into practical implementations"}}],[["$","script","script-0",{"src":"/_next/static/chunks/aa024a7c33692215.js","async":true}],["$","script","script-1",{"src":"/_next/static/chunks/e777581372c34758.js","async":true}]],["$","$L3",null,{"children":["$","$4",null,{"name":"Next.MetadataOutlet","children":"$@5"}]}]]}],"loading":null,"isPartial":false}
5:null
