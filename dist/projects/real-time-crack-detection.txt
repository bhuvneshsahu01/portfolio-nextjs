1:"$Sreact.fragment"
2:I[18359,["/_next/static/chunks/83018d334d73546b.js","/_next/static/chunks/57295dd6a09d9778.js"],"ThemeProvider"]
3:I[3265,["/_next/static/chunks/83018d334d73546b.js","/_next/static/chunks/57295dd6a09d9778.js"],"Navbar"]
4:I[39756,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"default"]
5:I[37457,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"default"]
6:I[58234,["/_next/static/chunks/83018d334d73546b.js","/_next/static/chunks/57295dd6a09d9778.js"],"Footer"]
8:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
9:"$Sreact.suspense"
b:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"ViewportBoundary"]
d:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"MetadataBoundary"]
f:I[68027,[],"default"]
:HL["/_next/static/chunks/fa058511ebf21f41.css","style"]
:HL["/_next/static/media/0c89a48fa5027cee-s.p.4564287c.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
0:{"P":null,"b":"f2NP6DA-LcO-nEx8dBFpm","c":["","projects","real-time-crack-detection"],"q":"","i":false,"f":[[["",{"children":["projects",{"children":[["slug","real-time-crack-detection","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/fa058511ebf21f41.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/_next/static/chunks/83018d334d73546b.js","async":true,"nonce":"$undefined"}],["$","script","script-1",{"src":"/_next/static/chunks/57295dd6a09d9778.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"inter_7b064e0d-module__MOT0tq__variable space_grotesk_4f9f433b-module__fJfFLG__variable antialiased min-h-screen flex flex-col","children":["$","$L2",null,{"children":[["$","$L3",null,{}],["$","main",null,{"className":"flex-1","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L6",null,{}]]}]}]}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":["$L7",[["$","script","script-0",{"src":"/_next/static/chunks/c9a0df57e17de942.js","async":true,"nonce":"$undefined"}],["$","script","script-1",{"src":"/_next/static/chunks/7bea0d5e1a502b84.js","async":true,"nonce":"$undefined"}]],["$","$L8",null,{"children":["$","$9",null,{"name":"Next.MetadataOutlet","children":"$@a"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],["$","$1","h",{"children":[null,["$","$Lb",null,{"children":"$@c"}],["$","div",null,{"hidden":true,"children":["$","$Ld",null,{"children":["$","$9",null,{"name":"Next.Metadata","children":"$@e"}]}]}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],false]],"m":"$undefined","G":["$f",[]],"S":true}
10:I[29019,["/_next/static/chunks/83018d334d73546b.js","/_next/static/chunks/57295dd6a09d9778.js","/_next/static/chunks/c9a0df57e17de942.js","/_next/static/chunks/7bea0d5e1a502b84.js"],"ProjectCaseStudy"]
7:["$","$L10",null,{"project":{"id":"1","slug":"real-time-crack-detection","title":"Real-Time Crack Detection & Segmentation","shortDescription":"Industrial-grade computer vision pipeline for structural crack detection using state-of-the-art models with full deployment.","longDescription":"Production-grade computer vision pipeline that detects and segments structural cracks in real-time with 95.3% mAP—15% better than existing solutions. Built at AlgoLabs for infrastructure monitoring.","category":"computer-vision","tags":["Computer Vision","Production ML","Docker","Streamlit"],"technologies":["YOLOv8","SAM","Detectron2","PyTorch","Docker","Streamlit","FastAPI","LabelMe"],"featured":true,"githubUrl":"https://github.com/bhuvneshsahu01/Real-Time-Crack-Detection-and-Segmentation","highlights":["Created custom dataset: 1,200+ images with LabelMe annotations, handling extreme class imbalance (cracks: 3% of pixels)","Benchmarked 3 SOTA models: YOLOv8 (fastest), SAM (best segmentation), Detectron2 (best balance)","Selected YOLOv8-L based on speed/accuracy trade-off: 95.3% mAP @ 30 FPS on RTX 3090","Built FastAPI backend + Streamlit frontend, containerized with Docker for edge deployment"],"impact":"Deployed at AlgoLabs - now processing 10K+ images/day in production. Demonstrates ability to build production CV systems from data collection through deployment.","problem":"Manual structural inspection is slow, expensive, and misses 20-30% of critical cracks. A single missed crack in a bridge can lead to catastrophic failure, costing lives and millions in repairs.","technicalApproach":["Dataset Creation: Built custom dataset with 1,200+ images using LabelMe, implementing careful class balancing strategies for extreme imbalance (cracks represent only 3% of pixels)","Model Selection: Systematically benchmarked YOLOv8 (optimized for speed), SAM (best segmentation quality), and Detectron2 (balanced performance)","Optimization: Selected YOLOv8-L for optimal speed/accuracy trade-off, achieving 95.3% mAP @ 30 FPS on RTX 3090","Deployment Architecture: Built FastAPI backend for model serving, Streamlit frontend for visualization, containerized entire stack with Docker for consistent edge deployment"],"results":["95.3% mAP on test set (vs 82% baseline Faster R-CNN) - 13 percentage point improvement","30 FPS inference speed - real-time capable for video processing","89.4% IoU on segmentation masks - high-quality pixel-level detection","Processing 10K+ images/day in production at AlgoLabs","91% inter-annotator agreement during dataset curation"],"challenges":["Class Imbalance: Cracks represent only 3% of pixels. Solution: Implemented focal loss and extensive data augmentation (flips, rotation, brightness adjustments)","Edge Deployment: Model too large for edge devices. Solution: Applied model quantization reducing size by 60% with <2% accuracy loss","Real-World Variability: Cracks appear under diverse conditions. Solution: Trained on varied lighting, angles, crack types, and surface materials","Segmentation vs Detection Trade-off: Balanced precision requirements with inference speed for real-time use"],"learnings":"Production computer vision is 20% model training, 80% handling edge cases, deployment, and monitoring. The model that achieves 95% accuracy in notebooks often fails in production due to distribution shift, lighting variations, and deployment constraints. Success requires systematic data collection, rigorous evaluation across diverse conditions, and production-first architecture decisions.","myRole":"Lead Engineer — Owned end-to-end pipeline from data collection and annotation through model training, optimization, and production deployment","productionization":{"cicd":"Containerized with Docker for consistent deployment across edge devices. Automated build pipeline ensures reproducible deployments.","monitoring":"Implemented latency tracking (45ms average CPU inference), accuracy monitoring on production data, and automated alerting for distribution drift.","rollback":"Model versioning with MLflow enables instant rollback to previous versions if accuracy degrades. Maintained 3 model versions for A/B testing.","optimization":"Applied TensorRT quantization (FP32 → INT8) reducing model size 60% and inference time to 45ms on CPU while maintaining 95%+ mAP. Enables real-time edge deployment."}}}]
c:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
11:I[27201,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"IconMark"]
e:[["$","title","0",{"children":"Real-Time Crack Detection & Segmentation | Bhuvnesh Sahu"}],["$","meta","1",{"name":"description","content":"Industrial-grade computer vision pipeline for structural crack detection using state-of-the-art models with full deployment."}],["$","meta","2",{"name":"author","content":"Bhuvnesh Sahu"}],["$","meta","3",{"name":"keywords","content":"Machine Learning Engineer,ML Engineer Portfolio,Production AI Engineer,GenAI Engineer,Computer Vision Engineer,LLM Engineer,Agentic AI,RAG,NLP,Deep Learning,Python,PyTorch,LangChain"}],["$","meta","4",{"name":"creator","content":"Bhuvnesh Sahu"}],["$","meta","5",{"name":"robots","content":"index, follow"}],["$","meta","6",{"property":"og:title","content":"Bhuvnesh Sahu | ML Engineer | Production GenAI & Computer Vision"}],["$","meta","7",{"property":"og:description","content":"Machine Learning Engineer building production AI systems. Shipped 5+ ML systems with measurable business impact."}],["$","meta","8",{"property":"og:url","content":"https://bhuvneshsahu.com"}],["$","meta","9",{"property":"og:site_name","content":"Bhuvnesh Sahu - ML Engineer Portfolio"}],["$","meta","10",{"property":"og:locale","content":"en_US"}],["$","meta","11",{"property":"og:image","content":"https://bhuvneshsahu.com/images/og-image.png"}],["$","meta","12",{"property":"og:image:width","content":"1200"}],["$","meta","13",{"property":"og:image:height","content":"630"}],["$","meta","14",{"property":"og:image:alt","content":"Bhuvnesh Sahu - ML Engineer | Production GenAI & Computer Vision"}],["$","meta","15",{"property":"og:type","content":"website"}],["$","meta","16",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","17",{"name":"twitter:title","content":"Bhuvnesh Sahu | ML Engineer | Production GenAI & Computer Vision"}],["$","meta","18",{"name":"twitter:description","content":"Machine Learning Engineer building production AI systems with measurable business impact."}],["$","meta","19",{"name":"twitter:image","content":"https://bhuvneshsahu.com/images/og-image.png"}],["$","link","20",{"rel":"icon","href":"/favicon.ico?favicon.0b3bf435.ico","sizes":"256x256","type":"image/x-icon"}],["$","$L11","21",{}]]
a:null
